{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c15ce3cd-cb9f-49f4-ac83-5b54d7d7d078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________PIPELINE RESULTS________________________\n",
      "Top 3 features from  SelectKBest :\n",
      "-  Xbox 360\n",
      "-  Bandai Namco Studios\n",
      "-  Blizzard Entertainment\n",
      "\n",
      "Scores for  SelectKBest :\n",
      "Mean Absolute Error:  5607777.777777778\n",
      "R^2 score: -0.011072460068845436\n",
      "________________________________________________________\n",
      "Top 3 features from  SelectFromModel :\n",
      "-  Weekday\n",
      "-  Game Boy\n",
      "-  Nintendo Switch\n",
      "\n",
      "Scores for  SelectFromModel :\n",
      "Mean Absolute Error:  6647313.055555556\n",
      "R^2 score: 0.03636138588046178\n",
      "________________________________________________________\n",
      "Top 3 features from  RFE :\n",
      "-  Weekday\n",
      "-  Game Boy\n",
      "-  Multi-platform\n",
      "\n",
      "Scores for  RFE :\n",
      "Mean Absolute Error:  6485090.833333333\n",
      "R^2 score: -0.09201565280949309\n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def fit_and_print_scores(pipeline, X_train, test_X, y_train, test_y):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    regression_name = pipeline.named_steps[\"regressor\"].__class__.__name__\n",
    "    feature_selection_name = pipeline.named_steps[\"feature_selection\"].__class__.__name__\n",
    "    test_predictions = pipeline.predict(test_X)\n",
    "    mae = mean_absolute_error(test_y, test_predictions)\n",
    "\n",
    "    r2 = r2_score(test_y, test_predictions)\n",
    "    \n",
    "    feature_selection_step = pipeline.named_steps['feature_selection']\n",
    "\n",
    "    # Get the selected features using the get_support() method\n",
    "    selected_features = feature_selection_step.get_support()\n",
    "\n",
    "    # Print the selected features\n",
    "    print(\"Top 3 features from \",feature_selection_name,\":\")\n",
    "    count = 0\n",
    "    for feature, selected in zip(X_train.columns, selected_features):\n",
    "        if selected:\n",
    "            if feature == \"Initial release date\":\n",
    "                print(\"-  Weekday\")\n",
    "            else:\n",
    "                print(\"- \", feature)\n",
    "            count += 1\n",
    "            if count == 3:\n",
    "                break\n",
    "    \n",
    "    print(\"\\nScores for \", feature_selection_name, \":\")\n",
    "    print(\"Mean Absolute Error: \" , mae)\n",
    "    print(\"R^2 score:\", r2)\n",
    "    print(\"________________________________________________________\")\n",
    "\n",
    "\n",
    "def transform_to_weekday(value):\n",
    "    date_format = \"%B %d, %Y\"\n",
    "    date_object = datetime.strptime(value, date_format)\n",
    "    return date_object.weekday()\n",
    "\n",
    "def transform_to_quarter(value):\n",
    "    # Perform your transformation logic here\n",
    "    date_format = \"%B %d, %Y\"\n",
    "    date_object = datetime.strptime(value, date_format)\n",
    "    return (date_object.month - 1) // 3 + 1\n",
    "\n",
    "def preprocess_multicat(dataFrame, columns, separator): \n",
    "    mlb = MultiLabelBinarizer() # Not possible on a pipeline https://github.com/scikit-learn/scikit-learn/issues/11309\n",
    "    for cat in columns:\n",
    "        dataFrame[cat] = dataFrame[cat].str.split(separator).apply(lambda x: [str(i).strip() for i in x])\n",
    "        encoded_features = mlb.fit_transform(dataFrame[cat])\n",
    "        encoded_df = pd.DataFrame(encoded_features, columns=mlb.classes_)\n",
    "        dataFrame = pd.concat([dataFrame, encoded_df], axis=1)\n",
    "    return dataFrame\n",
    "\n",
    "\n",
    "# Custom transformer to extract release quarter\n",
    "    # For some godforsaken reason, it did not recognize the release data as a Datetime object, so I had to apply a transform \n",
    "def extract_release_quarter(df):\n",
    "    df['Release Quarter'] = df['Initial release date'].apply(transform_to_quarter)\n",
    "    return df\n",
    "\n",
    "# Custom transformer to extract release day of week\n",
    "def extract_release_day_of_week(df):\n",
    "    # Could not get rid of the original column, so I replaced the values with the weekday column's values\n",
    "    df['Initial release date'] = df['Initial release date'].apply(transform_to_weekday)\n",
    "    return df\n",
    "\n",
    "def drop_column(df, column_to_drop):\n",
    "    return df.drop(column_to_drop)\n",
    "\n",
    "# Define the pipeline\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ] \n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "    ('release_quarter', FunctionTransformer(extract_release_quarter)),\n",
    "    ('release_day_of_week', FunctionTransformer(extract_release_day_of_week)),\n",
    "    #('drop_column', FunctionTransformer(drop_column, kw_args={'column_to_drop': 'Initial release date'}))\n",
    "    \n",
    "])\n",
    "\n",
    "# Define the column transformer for applying transformations to specific columns\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('release_date_transformer', pipeline, ['Initial release date']),\n",
    "    ('series_encoder', categorical_transformer, [\"Series\"])\n",
    "])\n",
    "\n",
    "regr_forest = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "           (\"feature_selection\", 'passthrough'),# placeholder for when we loop 3 different methods into it.\n",
    "           (\"regressor\", KNeighborsRegressor(n_neighbors=4))]\n",
    ")\n",
    "df = pd.read_csv('best-selling video games of all time.csv')  \n",
    "df = df.drop(df.index[:5]) # The top 5 are the outliers of the outliers, remove them.\n",
    "df = df.reset_index(drop=True) # and reset the index in case we loop with index later on\n",
    "\n",
    "categorical_features = [ \"Platform(s)\",\"Developer(s)\",  \"Publisher(s)\"] # not suited for OneHotEncoder\n",
    "df = preprocess_multicat(df, categorical_features, '/')\n",
    "\n",
    "X = pd.concat([df['Initial release date'], df.iloc[:, 8:], df['Series']], axis=1)\n",
    "\n",
    "y = df['Sales']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "print(\"________________________PIPELINE RESULTS________________________\")\n",
    "for feature_selection_method in [SelectKBest(k=4),SelectFromModel(GradientBoostingRegressor()),  RFE(estimator=LogisticRegression()) ]:\n",
    "    regr_forest.set_params(feature_selection=feature_selection_method)                                                                                              \n",
    "    fit_and_print_scores(regr_forest, train_X, test_X, train_y, test_y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3eb83b-0d6c-4ab3-bc76-81a5be6cbf15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
